<!DOCTYPE html>
<html lang="en">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>训练一个 GAN</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="../assets/built/screen%EF%B9%96v=792c672b3c.css" />

    <meta name="description" content="本文记录了训练 GAN 来生成二次元头像的过程。我们先从网上获取二次元头像数据集，训练一个生成器、训练一个判别器，来获取生产二次元头像的网络。" />
    <link rel="icon" href="../content/images/size/w256h256/2020/02/small-3.png" type="image/png" />
    <link rel="canonical" href="index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <link rel="amphtml" href="amp/index.html" />
    
    <meta property="og:site_name" content="Pion1eer" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="训练一个 GAN" />
    <meta property="og:description" content="本文记录了训练 GAN 来生成二次元头像的过程。我们先从网上获取二次元头像数据集，训练一个生成器、训练一个判别器，来获取生产二次元头像的网络。" />
    <meta property="og:url" content="https://www.ruanx.net/training-gan/" />
    <meta property="og:image" content="https://www.ruanx.net/content/images/2022/01/--.jpg" />
    <meta property="article:published_time" content="2021-02-28T02:32:40.000Z" />
    <meta property="article:modified_time" content="2022-01-16T02:27:51.000Z" />
    <meta property="article:tag" content="machine learning" />
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="训练一个 GAN" />
    <meta name="twitter:description" content="本文记录了训练 GAN 来生成二次元头像的过程。我们先从网上获取二次元头像数据集，训练一个生成器、训练一个判别器，来获取生产二次元头像的网络。" />
    <meta name="twitter:url" content="https://www.ruanx.net/training-gan/" />
    <meta name="twitter:image" content="https://www.ruanx.net/content/images/2022/01/--.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Ruan Xingzhi" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="machine learning" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="1250" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Pion1eer",
        "url": "https://www.ruanx.net/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://www.ruanx.net/content/images/size/w256h256/2020/02/small-3.png",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "Ruan Xingzhi",
        "image": {
            "@type": "ImageObject",
            "url": "https://www.ruanx.net/content/images/2020/05/blue.jpeg",
            "width": 1024,
            "height": 1024
        },
        "url": "https://www.ruanx.net/author/blue/",
        "sameAs": []
    },
    "headline": "训练一个 GAN",
    "url": "https://www.ruanx.net/training-gan/",
    "datePublished": "2021-02-28T02:32:40.000Z",
    "dateModified": "2022-01-16T02:27:51.000Z",
    "keywords": "machine learning",
    "description": "本文记录了训练 GAN 来生成二次元头像的过程。我们先从网上获取二次元头像数据集，训练一个生成器、训练一个判别器，来获取生产二次元头像的网络。",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://www.ruanx.net/"
    }
}
    </script>

    <meta name="generator" content="Ghost 5.8" />
    <link rel="alternate" type="application/rss+xml" title="Pion1eer" href="../rss/index.rss" />
    <script defer src="https://cdn.jsdelivr.net/npm/@tryghost/portal@~2.5/umd/portal.min.js" data-ghost="https://www.ruanx.net/" data-key="595acd8f13c14d79a10527399d" data-api="https://www.ruanx.net/ghost/api/content/" crossorigin="anonymous"></script><style id="gh-members-styles">.gh-post-upgrade-cta-content,
.gh-post-upgrade-cta {
    display: flex;
    flex-direction: column;
    align-items: center;
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
    text-align: center;
    width: 100%;
    color: #ffffff;
    font-size: 16px;
}

.gh-post-upgrade-cta-content {
    border-radius: 8px;
    padding: 40px 4vw;
}

.gh-post-upgrade-cta h2 {
    color: #ffffff;
    font-size: 28px;
    letter-spacing: -0.2px;
    margin: 0;
    padding: 0;
}

.gh-post-upgrade-cta p {
    margin: 20px 0 0;
    padding: 0;
}

.gh-post-upgrade-cta small {
    font-size: 16px;
    letter-spacing: -0.2px;
}

.gh-post-upgrade-cta a {
    color: #ffffff;
    cursor: pointer;
    font-weight: 500;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a:hover {
    color: #ffffff;
    opacity: 0.8;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a.gh-btn {
    display: block;
    background: #ffffff;
    text-decoration: none;
    margin: 28px 0 0;
    padding: 8px 18px;
    border-radius: 4px;
    font-size: 16px;
    font-weight: 600;
}

.gh-post-upgrade-cta a.gh-btn:hover {
    opacity: 0.92;
}</style>
    <script defer src="https://cdn.jsdelivr.net/npm/@tryghost/sodo-search@~1.1/umd/sodo-search.min.js" data-key="595acd8f13c14d79a10527399d" data-styles="https://cdn.jsdelivr.net/npm/@tryghost/sodo-search@~1.1/umd/main.css" data-sodo-search="https://www.ruanx.net/" crossorigin="anonymous"></script>
    <script defer src="../public/cards.min%EF%B9%96v=792c672b3c.js"></script>
    <link rel="stylesheet" type="text/css" href="../public/cards.min%EF%B9%96v=792c672b3c.css">
    <!-- link href="https://fonts.googleapis.com/css?family=Noto+Serif+SC&display=swap" rel="stylesheet" -->

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Fira+Mono&amp;family=Noto+Serif+SC&amp;display=swap" rel="stylesheet">

<style>.post-content,.post-card-excerpt{font-family: 'Noto Serif SC', "PingFang SC","Helvetica Neue",Helvetica,"Hiragino Sans GB","Microsoft YaHei","微软雅黑",Arial,sans-serif;}
    .post-full-content{font-size: 100%;}
    .post-full-custom-excerpt {font-size: 1.8rem;}
    .post-full-title {font-size:3.2rem;}
    .post-full-content blockquote{margin:20px;padding: 1em;  background-color: #3eb0ef14; }
    .post-full-content blockquote p {font-style:normal;}
    .post-full-image {display:none;}
    
    /* .post-full-content figcaption {margin: .4em 0 .5em  !important} */
    
    .kg-callout-card {width: 100%; margin-bottom: 1em;}
    
    .post-full-content figure {margin: 0.8em 0 1em;}
    
    p {margin: 0.2em 0 0.5em !important;}
    
    .post-full-content img{border-radius:5px;}
    
    code {font-family: 'Noto Serif SC';}
</style>


<style>:root {--ghost-accent-color: #15171A;}</style>

</head>
<body class="post-template tag-machine-learning">

    <div class="site-wrapper">

        

<header class="site-header">
    <div class="outer site-nav-main">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left-wrapper">
        <div class="site-nav-left">
                <a class="site-nav-logo" href="../index.html">Pion1eer</a>
            <div class="site-nav-content">
                    <ul class="nav">
    <li class="nav-home"><a href="../index.html">Home</a></li>
    <li class="nav-about"><a href="../about/index.html">About</a></li>
</ul>

                    <span class="nav-post-title dash">训练一个 GAN</span>
            </div>
        </div>
    </div>
    <div class="site-nav-right">
            <div class="social-links">
            </div>
                <a class="rss-button" href="https://feedly.com/i/subscription/feed/https://www.ruanx.net/rss/" title="RSS" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
</a>

    </div>
</nav>
    </div>
</div>

<script>
 MathJax = {
        tex:{
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
        svg:{
                fontCache: 'global'
            }
        }; 
    </script>
    <script src="https://cdn.staticfile.org/babel-polyfill/7.12.1/polyfill.min.js?features=es6"></script>
    <script type="text/javascript" id="MathJax-script" async  src="https://cdn.staticfile.org/mathjax/3.2.2/es5/tex-mml-chtml.js"></script>

<style>@media (prefers-color-scheme: light) {
		.post-full-content  
    pre{background:#fafafa;margin:10px 10px 20px 10px;border-style: solid;border-color:#DCDFE6;}
}
</style>

<link rel="stylesheet" href="https://cdn.ruanx.net/css/atom-one-dark.css">
<link rel="stylesheet" media="(prefers-color-scheme: light)" href="https://cdn.ruanx.net/css/atom-one-light.min.css">
<style>.post-full-content  code{font-family: 'Fira Mono', 'Jetbrains mono', 'ubuntu mono', consolas, 'monospace' !important;}
</style>

</header>


<main id="site-main" class="site-main outer">
    <div class="inner">

        <article class="post-full post tag-machine-learning no-image no-image">

            <header class="post-full-header">

                <section class="post-full-tags">
                    <a href="../tag/machine-learning/index.html">machine learning</a>
                </section>

                <h1 class="post-full-title">训练一个 GAN</h1>

                <p class="post-full-custom-excerpt">本文记录了训练 GAN 来生成二次元头像的过程。我们先从网上获取二次元头像数据集，训练一个生成器、训练一个判别器，来获取生产二次元头像的网络。</p>

                <div class="post-full-byline">

                    <section class="post-full-byline-content">

                        <ul class="author-list">
                            <li class="author-list-item">

                                <div class="author-card">
                                    <img class="author-profile-image" src="../content/images/size/w100/2020/05/blue.jpeg" alt="Ruan Xingzhi" />
                                    <div class="author-info">
                                        <div class="bio">
                                            <h2>Ruan Xingzhi</h2>
                                            <p>Welcome to my site and hope you have fun.</p>
                                            <p><a href="../author/blue/index.html">More posts</a> by Ruan Xingzhi.</p>
                                        </div>
                                    </div>
                                </div>

                                <a href="../author/blue/index.html" class="author-avatar">
                                    <img class="author-profile-image" src="../content/images/size/w100/2020/05/blue.jpeg" alt="Ruan Xingzhi" />
                                </a>

                            </li>
                        </ul>

                        <section class="post-full-byline-meta">
                            <h4 class="author-name"><a href="../author/blue/index.html">Ruan Xingzhi</a></h4>
                            <div class="byline-meta-content">
                                <time class="byline-meta-date" datetime="2021-02-28">28 Feb 2021</time>
                                <span class="byline-reading-time"><span class="bull">&bull;</span> 10 min read</span>
                            </div>
                        </section>

                    </section>


                </div>
            </header>


            <section class="post-full-content">
                <div class="post-content">
                    <p>　　我们的任务是训练一个 GAN 用于生成二次元头像。主要参考了李宏毅老师的 <a href="https://youtu.be/DQNNMiAP5lw">GAN 教程</a> ，数据集来源于李宏毅老师的 <a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html">作业 3</a>。</p><p>　　生成器是输入 100 维度的 latent vector，通过转置卷积和最后的全连接层，生成 64×64 的图像。</p><p>　　先简要说一下训练过程中遇到的问题。</p><ul><li>迭代若干次之后，生成图片为纯黑色。<br>降低学习率可以避免这种情况。</li><li>D 太强势，对真图直接标为 1.0，对假图直接标为 0.0，梯度很小，导致 G 学不到多少东西。<br>网上有人说「给标签加噪音」，有人说「改 k 值」。我这边把 k 值调得很低，可以缓解。另外降低了 D 的学习率，也有一些效果。</li><li>D 严重欠拟合，所有的图片都给出同样的分数。<br>我是调整网络结构之后缓解了这个情况。降低学习率似乎也有用。</li></ul><p>　　第一遍写代码，是自己搞的模型。生成器通过转置卷积层与卷积层的组合来造图片；判别器是 CNN，但是没有池化层（为了尽量少丢失信息），而是采用了 <code>stride = 2</code> 的卷积层来减少特征。代码如下：</p><figure class="kg-card kg-code-card"><pre><code class="language-python">import torch
import torch.nn as nn
import torchvision
import os
import numpy as np
import PIL.Image as Image
import itertools

import matplotlib.pyplot as plt</code></pre><figcaption>▲ 引入库</figcaption></figure><figure class="kg-card kg-code-card"><pre><code class="language-python">batchsize = 32

images_dataset = torchvision.datasets.ImageFolder(
    os.path.join('data'),
    transform=torchvision.transforms.Compose([
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Resize(64)]))

realimg_loader = torch.utils.data.DataLoader(
    images_dataset, 
    batch_size=batchsize,
    shuffle=True)

realimg_iter = iter(realimg_loader)

sample_x, _ = next(iter(realimg_loader))</code></pre><figcaption>▲&nbsp;引入数据集</figcaption></figure><pre><code class="language-python">plt.figure(figsize=(10, 10))
plt.imshow(torchvision.utils.make_grid(sample_x).numpy().transpose((1, 2, 0)))</code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../content/images/2021/03/image.png" class="kg-image" alt loading="lazy" width="960" height="450" srcset="../content/images/size/w600/2021/03/image.png 600w, ../content/images/2021/03/image.png 960w" sizes="(min-width: 720px) 720px"><figcaption>▲ 数据集样例</figcaption></figure><p>　　接下来定义生成器：先经过一个全连接层，再用转置卷积层、卷积层来生成更大的图片；最后输出 64×64 的图。激活函数用 relu，输出层用 tanh。这里我在输出时规范化到 $[0, 1]$ 之间，之后实践证明这不是很好的方案。应该不改这个 tanh，而是把真实图像规范化到 $[-1, 1]$ 内。</p><pre><code class="language-python">class Gen(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.fc = nn.Linear(100, 32*16*16)
        
        self.upsamp1 = nn.ConvTranspose2d(32, 128, 4, stride=2)
        self.conv1 = nn.Conv2d(128, 128, 4)
        
        self.upsamp2 = nn.ConvTranspose2d(128, 128, 4, stride=2)
        self.conv2 = nn.Conv2d(128, 64, 4)
        
        self.conv3 = nn.Conv2d(64, 3, 4, padding=3)
        
    def forward(self, x):
        x = self.fc(x)
        x = torch.relu(x)
        x = x.view(-1, 32, 16, 16)
        
        x = self.upsamp1(x)
        x = self.conv1(x)
        x = torch.relu(x)
        
        x = self.upsamp2(x)
        x = self.conv2(x)
        x = torch.relu(x)
        
        x = self.conv3(x)
        x = torch.tanh(x)
        
        return x / 2 + .5</code></pre><p>　　判别器，一个简单的 CNN，没有池化。</p><pre><code class="language-python">class Dis(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.conv1 = nn.Conv2d(3, 32, 4, stride=2)
        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)
        self.conv3 = nn.Conv2d(64, 128, 4, stride=2)
        self.conv4 = nn.Conv2d(128, 256, 4, stride=2)
        self.fc = nn.Linear(256 * 2 * 2, 1)
    
    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = torch.relu(self.conv3(x))
        x = torch.relu(self.conv4(x))
        
        x = x.view(-1, 256 * 2 * 2)
        x = torch.sigmoid(self.fc(x))

        return x</code></pre><p>　　采用 Adam 优化器：</p><pre><code class="language-python">gen = Gen()
optim_gen = torch.optim.Adam(gen.parameters(), lr=0.0002, betas=(.5, .999))

dis = Dis()
optim_dis = torch.optim.Adam(dis.parameters(), lr=0.0002, betas=(.5, .999))</code></pre><p>　　训练这两个网络的代码：</p><pre><code class="language-python">def train_dis(cnt, gen, dis):
    gen.requires_grad_(False)
    dis.requires_grad_(True)
    
    for x in range(cnt):
        fake_img = gen(torch.randn([batchsize, 100]))
        real_img, _ = next(realimg_iter)

        optim_dis.zero_grad()
        loss = - (torch.sum(torch.log(1 - dis(fake_img))) + torch.sum(torch.log(dis(real_img)))) / batchsize
#         print(f'train dis, round {x} loss={loss.item()}')
        
        loss.backward()
        optim_dis.step()
    
#     with torch.no_grad():
#         correct_real = sum(dis(real_img) &gt; .5)
#         correct_fake = sum(dis(fake_img) &lt; .5)
#         print(f'correct_real: {correct_real.item()} / {batchsize}, correct_fake: {correct_fake.item()} / {batchsize}')

def train_gen(cnt, gen, dis):
    gen.requires_grad_(True)
    dis.requires_grad_(False)
    
    for x in range(cnt):
        fake_img = gen(torch.randn([batchsize, 100]))
        
        optim_gen.zero_grad()
        loss = - torch.sum(torch.log(dis(fake_img))) / batchsize
#         print(f'train gen, round {x} loss={loss.item()}')
        
        loss.backward()
        optim_gen.step()
    
#     with torch.no_grad():
#         success_cnt = sum(dis(fake_img) &gt; .5)
#         print(f'success: {success_cnt.item()} / {batchsize}')
</code></pre><p>　　接下来开始迭代。注意 GAN 非常不稳定，随时可能过拟合、模式坍塌，需要回档调参数继续训练。所以模型要定期存 checkpoint。</p><pre><code class="language-python">for x in range(2000):
    print(f'&gt; round {x}\n')
    
    realimg_iter = itertools.cycle(realimg_loader)
    
    for c in range(10):
        train_dis(5, gen, dis)
        train_gen(1, gen, dis)
    
    with torch.no_grad():
        test = gen(torch.randn([batchsize, 100]))
    show_img(test[0])
    
    if x % 100 == 99:
        torch.save({
            'gen': gen.state_dict(),
            'optim_gen': optim_gen.state_dict(),
            'dis': dis.state_dict(),
            'optim_dis': optim_dis.state_dict()
        }, f'checkpoint0227-{x}.pth')</code></pre><p>　　几百次迭代之后，产出如下：</p><figure class="kg-card kg-image-card"><img src="../content/images/2021/03/image-1.png" class="kg-image" alt loading="lazy" width="1280" height="432" srcset="../content/images/size/w600/2021/03/image-1.png 600w, ../content/images/size/w1000/2021/03/image-1.png 1000w, ../content/images/2021/03/image-1.png 1280w" sizes="(min-width: 720px) 720px"></figure><p>　　再进行一些迭代之后结果如下。注意到已经产生了模式坍塌。</p><figure class="kg-card kg-image-card"><img src="../content/images/2021/03/image-3.png" class="kg-image" alt loading="lazy" width="1280" height="235" srcset="../content/images/size/w600/2021/03/image-3.png 600w, ../content/images/size/w1000/2021/03/image-3.png 1000w, ../content/images/2021/03/image-3.png 1280w" sizes="(min-width: 720px) 720px"></figure><p>　　调整参数之后训练几千轮，最终结果如下：</p><figure class="kg-card kg-image-card"><img src="../content/images/2021/03/image-2.png" class="kg-image" alt loading="lazy" width="1302" height="832" srcset="../content/images/size/w600/2021/03/image-2.png 600w, ../content/images/size/w1000/2021/03/image-2.png 1000w, ../content/images/2021/03/image-2.png 1302w" sizes="(min-width: 720px) 720px"></figure><p>　　总之就是非常抽象。挑了几张好看一点的，与诸君共赏：</p><figure class="kg-card kg-gallery-card kg-width-wide"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="../content/images/2021/03/2.png" width="251" height="251" loading="lazy" alt></div><div class="kg-gallery-image"><img src="../content/images/2021/03/1.png" width="251" height="251" loading="lazy" alt></div><div class="kg-gallery-image"><img src="../content/images/2021/03/6.png" width="251" height="251" loading="lazy" alt></div></div><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="../content/images/2021/03/10.png" width="251" height="251" loading="lazy" alt></div><div class="kg-gallery-image"><img src="../content/images/2021/03/13.png" width="251" height="251" loading="lazy" alt></div><div class="kg-gallery-image"><img src="../content/images/2021/03/14.png" width="251" height="251" loading="lazy" alt></div></div><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="../content/images/2021/03/30.png" width="251" height="251" loading="lazy" alt></div><div class="kg-gallery-image"><img src="../content/images/2021/03/31.png" width="251" height="251" loading="lazy" alt></div><div class="kg-gallery-image"><img src="../content/images/2021/03/3.png" width="251" height="251" loading="lazy" alt></div></div></div></figure><p>　　看起来确实像个人，反正比我画得好。</p><hr><p>　　3 月 1 日，我用 DCGAN 重写了一遍。主要参考了 PyTorch 的官方教程。</p><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"><div class="kg-bookmark-content"><div class="kg-bookmark-title">DCGAN Tutorial — PyTorch Tutorials 1.7.1 documentation</div><div class="kg-bookmark-description"></div><div class="kg-bookmark-metadata"></div></div><div class="kg-bookmark-thumbnail"><img src="https://pytorch.org/tutorials/_images/sphx_glr_dcgan_faces_tutorial_001.png"></div></a></figure><p>　　DCGAN 引入了 BatchNorm 来加快收敛、改善效果，另外取消了全连接层，使得生成器和判别器都是全卷积网络。</p><figure class="kg-card kg-image-card"><img src="../content/images/2021/03/image-11.png" class="kg-image" alt loading="lazy" width="924" height="397" srcset="../content/images/size/w600/2021/03/image-11.png 600w, ../content/images/2021/03/image-11.png 924w" sizes="(min-width: 720px) 720px"></figure><pre><code class="language-python">import torch
import torch.nn as nn
import torchvision
import os
import numpy as np
import PIL.Image as Image
import itertools

import matplotlib.pyplot as plt</code></pre><pre><code class="language-python">batchsize = 128

learning_rate_gen = 0.0002
learning_rate_dis = 0.0002
beta1 = 0.5

dim_latent_vector = 100
num_gen_feature_map = 64
num_dis_feature_map = 64

num_gen_output_channel = 3

k = 1</code></pre><figure class="kg-card kg-code-card"><pre><code class="language-python">images_dataset = torchvision.datasets.ImageFolder(
    os.path.join('data'),
    transform=torchvision.transforms.Compose([
        torchvision.transforms.Resize(64),
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Normalize([.5, .5, .5], [.5, .5, .5])]))

realimg_loader = torch.utils.data.DataLoader(
    images_dataset, 
    batch_size=batchsize,
    shuffle=True)

images_dataset</code></pre><figcaption>▲ 引入数据集。注意这里做了归一化</figcaption></figure><p>　　现在我们的图像，无论是真实的图，还是生成的图，都是 $[-1, 1]$ 范围内的了。写一点用于输出图像的辅助函数：</p><pre><code class="language-python">realimg_iter = iter(realimg_loader)
sample_x, _ = next(iter(realimg_loader))

data_to_image = torchvision.transforms.Compose([
    torchvision.transforms.Normalize([-1, -1, -1], [2, 2, 2]),
    torchvision.transforms.ToPILImage()])

def show_img(x):
    plt.imshow(data_to_image(x))

def show_grid(x, title=None):
    plt.figure(figsize=(10, 10))
    plt.title(title)
    plt.imshow(data_to_image(torchvision.utils.make_grid(x)))
    plt.show()

show_grid(sample_x[:32], 'training dataset');</code></pre><figure class="kg-card kg-image-card"><img src="../content/images/2021/03/image-4.png" class="kg-image" alt loading="lazy" width="884" height="410" srcset="../content/images/size/w600/2021/03/image-4.png 600w, ../content/images/2021/03/image-4.png 884w" sizes="(min-width: 720px) 720px"></figure><p>　　这一次网络很大，我们采用 GPU 来训练：</p><pre><code class="language-python">device = torch.device("cuda:0")
device

# device(type='cuda', index=0)</code></pre><p>　　根据 paper，需要把网络的初始参数调成 $N(0, 0.02)$，我们写一个函数，用于接下来初始化网络。</p><pre><code class="language-python">def set_layer_init_weight(layer):
    if 'Conv' in layer.__class__.__name__:
        nn.init.normal_(layer.weight.data, 0, 0.02)
    elif 'BatchNorm' in layer.__class__.__name__:
        nn.init.normal_(layer.weight.data, 1, 0.02)
        nn.init.constant_(layer.bias.data, 0)</code></pre><p>　　定义生成器和判别器：</p><pre><code class="language-python">class Gen(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.main = nn.Sequential(
            nn.ConvTranspose2d(dim_latent_vector, num_gen_feature_map * 8, 4, bias=False),
            nn.BatchNorm2d(num_gen_feature_map * 8),
            nn.ReLU(True),
            
            nn.ConvTranspose2d(num_gen_feature_map * 8, num_gen_feature_map * 4, 4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_gen_feature_map * 4),
            nn.ReLU(True),
            
            nn.ConvTranspose2d(num_gen_feature_map * 4, num_gen_feature_map * 2, 4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_gen_feature_map * 2),
            nn.ReLU(True),
            
            nn.ConvTranspose2d(num_gen_feature_map * 2, num_gen_feature_map, 4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_gen_feature_map),
            nn.ReLU(True),
            
            nn.ConvTranspose2d(num_gen_feature_map, num_gen_output_channel, 4, stride=2, padding=1, bias=False),
            nn.Tanh()
        )
        
    def forward(self, x):
        return self.main(x)
        
net_gen = Gen().to(device)
net_gen.apply(set_layer_init_weight)

net_gen</code></pre><figure class="kg-card kg-image-card kg-width-wide"><img src="../content/images/2021/03/image-5.png" class="kg-image" alt loading="lazy" width="1390" height="499" srcset="../content/images/size/w600/2021/03/image-5.png 600w, ../content/images/size/w1000/2021/03/image-5.png 1000w, ../content/images/2021/03/image-5.png 1390w" sizes="(min-width: 1200px) 1200px"></figure><pre><code class="language-python">class Dis(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.main = nn.Sequential(
            nn.Conv2d(num_gen_output_channel, num_dis_feature_map, 4, stride=2, padding=1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(num_dis_feature_map, num_dis_feature_map * 2, 4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_dis_feature_map * 2),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(num_dis_feature_map * 2, num_dis_feature_map * 4, 4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_dis_feature_map * 4),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(num_dis_feature_map * 4, num_dis_feature_map * 8, 4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_dis_feature_map * 8),
            nn.LeakyReLU(0.2, inplace=True),
            
            nn.Conv2d(num_dis_feature_map * 8, 1, 4, bias=False),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        return self.main(x)
        
net_dis = Dis().to(device)
net_dis.apply(set_layer_init_weight)

net_dis</code></pre><figure class="kg-card kg-image-card kg-width-wide"><img src="../content/images/2021/03/image-6.png" class="kg-image" alt loading="lazy" width="1310" height="469" srcset="../content/images/size/w600/2021/03/image-6.png 600w, ../content/images/size/w1000/2021/03/image-6.png 1000w, ../content/images/2021/03/image-6.png 1310w" sizes="(min-width: 1200px) 1200px"></figure><p>　　定义损失函数和优化器：</p><pre><code class="language-python">criterion = nn.BCELoss()

fixed_noise = torch.randn(64, dim_latent_vector, 1, 1, device=device)

label_real = 1.0
label_fake = 0.0

optim_gen = torch.optim.Adam(net_gen.parameters(), lr=learning_rate_gen, betas=(beta1, 0.999))
optim_dis = torch.optim.Adam(net_dis.parameters(), lr=learning_rate_dis, betas=(beta1, 0.999))</code></pre><p>　　训练：</p><pre><code class="language-python">loss_gen = []
loss_dis = []
iter_count = 0

def train_epoch():
    global iter_count
    
    for i, real_data in enumerate(realimg_loader):
        
        # 训练 dis，maximize log(D(x)) + log(1 - D(G(z)))
        
        for x in range(k):
            net_dis.zero_grad()
            real_data_gpu = real_data[0].to(device)

            this_data_size = real_data[0].size(0)

            label = torch.full((this_data_size, ), label_real, device=device)
            output = net_dis(real_data_gpu).view(-1)

            err_dis_real = criterion(output, label)
            err_dis_real.backward()

            avg_real_score = output.mean().item()


            noise = torch.randn(this_data_size, dim_latent_vector, 1, 1, device=device)
            fake_data_gpu = net_gen(noise)
            label.fill_(label_fake)
            output = net_dis(fake_data_gpu.detach()).view(-1)
            err_dis_fake = criterion(output, label)
            err_dis_fake.backward()

            avg_fake_score = output.mean().item()

            err_dis = err_dis_real + err_dis_fake

            optim_dis.step()
        
        # 训练 gen, maximize log(D(G(z)))
        
        net_gen.zero_grad()
        label.fill_(label_real)
        
        output = net_dis(fake_data_gpu).view(-1)    # 复用刚刚训练 dis 时生成的假图
        err_gen = criterion(output, label)
        err_gen.backward()
        
        avg_fake_score_after = output.mean().item() # dis 训练一次之后，再判断假图的打分

        optim_gen.step()
        
        
        if i % 50 == 0:
            print(f'iter {iter_count} [{i}/{len(realimg_loader)}] dis loss: {err_dis.item()} gen loss: {err_gen.item()}')
            print(f'D(real): {avg_real_score} D(fake): {avg_fake_score} -&gt; {avg_fake_score_after}')
        
        loss_gen.append(err_gen.item())
        loss_dis.append(err_dis.item())

        
        if i % 50 == 0:
            with torch.no_grad():
                new_fake_img = net_gen(fixed_noise).detach().cpu()
            show_grid(new_fake_img[:32])
            
        iter_count += 1</code></pre><p>　　于是就写完了。来看一下效果：</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../content/images/2021/03/1-1.png" class="kg-image" alt loading="lazy" width="598" height="314"><figcaption>▲&nbsp;初始</figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../content/images/2021/03/2-1.png" class="kg-image" alt loading="lazy" width="598" height="314"><figcaption>▲ 50&nbsp;次迭代</figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><img src="../content/images/2021/03/3-1.png" class="kg-image" alt loading="lazy" width="598" height="314"><figcaption>▲ 100&nbsp;次迭代</figcaption></figure><p>　　可见 DCGAN 比我们之前的模型生成能力强很多。1000 次迭代之后是下面的样子：</p><figure class="kg-card kg-image-card"><img src="../content/images/2021/03/image-8.png" class="kg-image" alt loading="lazy" width="598" height="314"></figure><p>　　48000 次迭代之后，成品如下：</p><figure class="kg-card kg-image-card"><img src="../content/images/2021/03/image-9.png" class="kg-image" alt loading="lazy" width="598" height="314"></figure><p>　　当然仍然很不真实，但比我们旧模型还是稍好一些。我们旧模型有类似抽象画的纹理，DCGAN 生成的图没有这种纹理。选了一些 DCGAN 产品，奇图共赏：</p><figure class="kg-card kg-gallery-card kg-width-wide"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="../content/images/2021/03/4.png" width="251" height="251" loading="lazy" alt></div><div class="kg-gallery-image"><img src="../content/images/2021/03/3-2.png" width="251" height="251" loading="lazy" alt></div></div><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="../content/images/2021/03/1-2.png" width="251" height="251" loading="lazy" alt></div><div class="kg-gallery-image"><img src="../content/images/2021/03/2-2.png" width="251" height="251" loading="lazy" alt></div></div></div></figure>
                </div>
            </section>


            <div id="gitalk-container"></div>

            <link rel="stylesheet" href="https://cdn.staticfile.org/gitalk/1.6.2/gitalk.css">
            <script src="https://cdn.staticfile.org/gitalk/1.6.2/gitalk.min.js"></script>

            <script>
                const gitalk = new Gitalk({

                    proxy: 'https://cors.pion1eer.workers.dev/?https://github.com/login/oauth/access_token',

                    clientID: '9f7e67174f5ab8b1a2b9',
                    clientSecret: 'ddee425a0b50ed02a05fdedb1a4ea039e01b3170',
                    repo: 'blogComment',
                    owner: 'Ruanxingzhi',
                    admin: ['Ruanxingzhi'],
                    id: location.pathname,      // Ensure uniqueness and length less than 50
                    distractionFreeMode: false  // Facebook-like distraction free mode

                    });

                gitalk.render('gitalk-container');
            </script>

        </article>

    </div>
</main>

<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
                <article class="read-next-card">
                    <header class="read-next-card-header">
                        <h3><span>More in</span> <a href="../tag/machine-learning/index.html">machine learning</a></h3>
                    </header>
                    <div class="read-next-card-content">
                        <ul>
                            <li>
                                <h4><a href="../lenet/index.html">LeNet：第一个卷积神经网络</a></h4>
                                <div class="read-next-card-meta">
                                    <p><time datetime="2021-02-24">24 Feb 2021</time> –
                                        11 min read</p>
                                </div>
                            </li>
                        </ul>
                    </div>
                    <footer class="read-next-card-footer">
                        <a href="../tag/machine-learning/index.html">1 post
                            →</a>
                    </footer>
                </article>

                <article class="post-card post tag-crypto no-image no-image">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../a-crypto-problem/index.html">

            <header class="post-card-header">
                    <div class="post-card-primary-tag">Crypto</div>
                <h2 class="post-card-title">一道密码学趣题</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>我们讨论了 2020 年信息安全国赛华南赛区的一道密码学题目。整体来看不太难，但需要考虑一些细节。这也是一道典型的概率性成功、需要爆破的问题。</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Ruan Xingzhi
                    </div>
            
                    <a href="../author/blue/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../content/images/size/w100/2020/05/blue.jpeg" alt="Ruan Xingzhi" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/blue/index.html">Ruan Xingzhi</a></span>
                <span class="post-card-byline-date"><time datetime="2021-03-09">9 Mar 2021</time> <span class="bull">&bull;</span> 9 min read</span>
            </div>
        </footer>

    </div>

</article>

                <article class="post-card post tag-machine-learning tag-algorithm no-image no-image">


    <div class="post-card-content">

        <a class="post-card-content-link" href="../lenet/index.html">

            <header class="post-card-header">
                    <div class="post-card-primary-tag">machine learning</div>
                <h2 class="post-card-title">LeNet：第一个卷积神经网络</h2>
            </header>

            <section class="post-card-excerpt">
                    <p>LeNet 是 Yann LeCun 等人在上世纪 90 年代提出的网络模型，用于手写数字的识别。本文介绍了该模型，并提供 PyTorch 实现。</p>
            </section>

        </a>

        <footer class="post-card-meta">
            <ul class="author-list">
                <li class="author-list-item">
            
                    <div class="author-name-tooltip">
                        Ruan Xingzhi
                    </div>
            
                    <a href="../author/blue/index.html" class="static-avatar">
                        <img class="author-profile-image" src="../content/images/size/w100/2020/05/blue.jpeg" alt="Ruan Xingzhi" />
                    </a>
                </li>
            </ul>
            <div class="post-card-byline-content">
                <span><a href="../author/blue/index.html">Ruan Xingzhi</a></span>
                <span class="post-card-byline-date"><time datetime="2021-02-24">24 Feb 2021</time> <span class="bull">&bull;</span> 11 min read</span>
            </div>
        </footer>

    </div>

</article>
        </div>
    </div>
</aside>




        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="../index.html">Pion1eer</a> &copy; 2023</section>
                <nav class="site-footer-nav">
                    <a href="http://beian.miit.gov.cn/" target="_blank">湘ICP备20008720号-1</a>
                    <a href="../index.html">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

<!--

    <div class="subscribe-success-message">
        <a class="subscribe-close" href="javascript:;"></a>
        You've successfully subscribed to Pion1eer!
    </div>

    <div id="subscribe" class="subscribe-overlay">
        <a class="subscribe-close" href="#"></a>
        <div class="subscribe-overlay-content">
            <div class="subscribe-form">
                <h1 class="subscribe-overlay-title">Subscribe to Pion1eer</h1>
                <p class="subscribe-overlay-description">Stay up to date! Get all the latest & greatest posts delivered straight to your inbox</p>
                <form data-members-form="subscribe">
                    <div class="form-group">
                        <input class="subscribe-email" data-members-email placeholder="youremail@example.com"
                            autocomplete="false" />
                        <button class="button primary" type="submit">
                            <span class="button-content">Subscribe</span>
                            <span class="button-loader"><svg version="1.1" id="loader-1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px"
    y="0px" width="40px" height="40px" viewBox="0 0 40 40" enable-background="new 0 0 40 40" xml:space="preserve">
    <path opacity="0.2" fill="#000" d="M20.201,5.169c-8.254,0-14.946,6.692-14.946,14.946c0,8.255,6.692,14.946,14.946,14.946
s14.946-6.691,14.946-14.946C35.146,11.861,28.455,5.169,20.201,5.169z M20.201,31.749c-6.425,0-11.634-5.208-11.634-11.634
c0-6.425,5.209-11.634,11.634-11.634c6.425,0,11.633,5.209,11.633,11.634C31.834,26.541,26.626,31.749,20.201,31.749z" />
    <path fill="#000" d="M26.013,10.047l1.654-2.866c-2.198-1.272-4.743-2.012-7.466-2.012h0v3.312h0
C22.32,8.481,24.301,9.057,26.013,10.047z">
        <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 20 20" to="360 20 20"
            dur="0.5s" repeatCount="indefinite" />
    </path>
</svg></span>
                        </button>
                    </div>
                    <div class="message-success">
                        <strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
                    </div>
                    <div class="message-error">
                        Please enter a valid email address!
                    </div>
                </form>
            </div>
        </div>
    </div>

-->

    <script
        src="https://cdn.ruanx.net/js/jquery.min.js"
        integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
        crossorigin="anonymous">
    </script>
    <script src="../assets/built/casper%EF%B9%96v=792c672b3c.js"></script>

    <script>
        // Parse the URL parameter
        function getParameterByName(name, url) {
            if (!url) url = window.location.href;
            name = name.replace(/[\[\]]/g, "\\$&");
            var regex = new RegExp("[?&]" + name + "(=([^&#]*)|&|#|$)"),
                results = regex.exec(url);
            if (!results) return null;
            if (!results[2]) return '';
            return decodeURIComponent(results[2].replace(/\+/g, " "));
        }

        // Give the parameter a variable name
        var action = getParameterByName('action');

        $(document).ready(function () {
            if (action == 'subscribe') {
                $('body').addClass("subscribe-success");
            }

            $('.subscribe-success-message .subscribe-close').click(function () {
                $('.subscribe-success-message').addClass('close');
            });

            // Reset form on opening subscrion overlay
            $('.subscribe-button').click(function() {
                $('.subscribe-overlay form').removeClass();
                $('.subscribe-email').val('');
            });
        });
    </script>

    <script>
    $(document).ready(function () {
        // FitVids - start
        var $postContent = $(".post-full-content");
        $postContent.fitVids();
        // FitVids - end

        // Replace nav with title on scroll - start
        Casper.stickyNavTitle({
            navSelector: '.site-nav-main',
            titleSelector: '.post-full-title',
            activeClass: 'nav-post-title-active'
        });
        // Replace nav with title on scroll - end

        // Hover on avatar
        var hoverTimeout;
        $('.author-list-item').hover(function () {
            var $this = $(this);

            clearTimeout(hoverTimeout);

            $('.author-card').removeClass('hovered');
            $(this).children('.author-card').addClass('hovered');

        }, function () {
            var $this = $(this);

            hoverTimeout = setTimeout(function () {
                $this.children('.author-card').removeClass('hovered');
            }, 800);
        });
    });
</script>

<script src="https://cdn.staticfile.org/highlight.js/10.1.1/highlight.min.js"></script>
<script >hljs.initHighlightingOnLoad();</script>



    <style>.kg-bookmark-metadata > .kg-bookmark-publisher:before {
    content: "" !important; 
    margin: 0 !important;
}
</style>

</body>
</html>
